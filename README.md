# TV Transcript Scraper â€“ Phase 1 ğŸš€

## Overview
This is **Phase 1** of a TV transcript scraper designed to pull, clean, and structure dialogue from ForeverDreaming. Because, letâ€™s be honest, finding structured TV dialogue data is so much harder than it should be.

Itâ€™s a working prototypeâ€”**far from perfect**, but it gets the job done. Right now, it scrapes, cleans, and does some basic analysis. Future iterations will hopefully be **smarter, faster, and more robust**.

---

## How It Works ğŸ”
1. **Find transcripts** â€“ Enter a TV show name, and the scraper locates available transcripts.  
2. **Clean up the mess** â€“ Removes HTML, timestamps, and other junk.  
3. **Tag & categorize** â€“ Uses simple keyword matching to categorize content.  
4. **Sentiment analysis (lightweight)** â€“ Because why not?  
5. **Output to CSV** â€“ Structured data, ready for analysis.  

---

## Installation & Running
```bash
git clone https://github.com/yourusername/tv-transcript-analysis.git
cd tv-transcript-analysis
pip install -r requirements.txt
python tv_transcript.py
```

---

## Project Structure ğŸ—‚ï¸
- **`tv_transcript.py`** â€“ The main script that runs everything.  
- **`data/`** â€“ Where raw transcripts live.  
- **`reports/`** â€“ Processed CSV outputs.  

---

## Issues & Future Work
### ğŸš¨ Known Bugs
- **Regex extraction is messy** â€“ Season/episode metadata parsing is unreliable.  
- **Noise from forums** â€“ Sometimes picks up random forum posts as "episodes."  
- **Keyword matching is dumb** â€“ Too many false positives, needs better heuristics.  
- **Sentiment analysis is shallow** â€“ Detects words like â€œsorryâ€ but fails on sarcasm.  

### ğŸ”œ Whatâ€™s Next? (Phase 2)
- **Scale up** â€“ Full season handling, retry logic, proxy rotation.  
- **Database support** â€“ PostgreSQL or MongoDB for structured storage.  
- **Smarter annotations** â€“ Expand keyword matching, explore weak supervision.  
- **Machine learning** â€“ Maybe throw BERT at it for classification?  

---

## License ğŸ“œ
**MIT** â€“ Use it, break it, improve it, share it.

ğŸš€ Built in **July 2023** as part of a research project at MIT GOV/Lab.
